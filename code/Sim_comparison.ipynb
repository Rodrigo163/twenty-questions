{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing interpolation methods\n",
    "\n",
    "When loading the Twenty-Questions class, we included two different similarity measures to choose from. These similarity functions are the main element of the interpolation method, which allows us to integrate new information into out Knowledge Base.\n",
    "In this notebook we will evaluate which interpolation method seems to work best.\n",
    "In order to do this we will evaluate their outputs using animals that we know are highly correlated (wolf and dog for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "class TwentyQuestions():\n",
    "    \"\"\"\n",
    "    Plays twenty questions.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kn_file_name, stats_file_name, sim_measure = 'ours', quick_endgame = False):\n",
    "\n",
    "        self.kn_file_name = kn_file_name\n",
    "        self.kn = pd.read_csv(self.kn_file_name)\n",
    "\n",
    "        self.y = self.kn['animal']\n",
    "        self.new_row = 0\n",
    "        self.temp = 0\n",
    "        self.X = self.kn.loc[:, self.kn.columns != 'animal']\n",
    "        self.counter = 1\n",
    "        self.answers = dict()\n",
    "\n",
    "        # Whether or not to use the fancy endgame_lose() function or to use quick_endgame_lose().\n",
    "        # Default = False, i.e. use endgame_lose().\n",
    "        self.quick_endgame = quick_endgame\n",
    "\n",
    "        # By default we will be using our similarity measure. Options are 'ours' or 'corr'\n",
    "        self.sim_measure = sim_measure\n",
    "\n",
    "        # Dataframe with our statistics\n",
    "        # stats consist of only two columns:\n",
    "            #n_questions: the first one contains the number of questions asked in that play\n",
    "            #result: the second one containts the result. 0 for a win, 1 for a loss in which the animal was already in the dataset and 2 for a new animal\n",
    "        self.stats_file_name = stats_file_name\n",
    "\n",
    "        # If the file doesn't already exist in current directory, create it.\n",
    "        if self.stats_file_name not in set(os.listdir()):\n",
    "            with open(self.stats_file_name, 'w') as f:\n",
    "                f.write('n_questions,result\\n')\n",
    "\n",
    "        self.stats = pd.read_csv(self.stats_file_name)\n",
    "\n",
    "        # Initialise the \"probability\" distribution over y: a uniform prior of 20 (arbitrary number) per animal.\n",
    "        self.y_probdist = pd.DataFrame(self.y)\n",
    "        self.y_probdist['prob'] = np.repeat(20, len(self.y))\n",
    "        self.y_probdist = self.y_probdist.set_index('animal')['prob']\n",
    "\n",
    "        # Records which features are subjective, rather subjective, and objective (we will ask about objective features first).\n",
    "        self.subj_feats = ['furry', 'smelly', 'smart', 'a_long_life', 'fast', 'slow', 'useful_to_humans', 'sleep_a_lot',\n",
    "                           'dangerous']\n",
    "        self.rather_subj_feats = ['have_hair', 'predator', 'venomous', 'type_of_pet', 'black', 'white-colored', 'blue-colored', 'a_brown_color', 'gray-colored', 'spots',                                   'hooves', 'paws', 'in_a_group', 'endangered', 'on_a_farm', 'in_safari_areas', 'in_the_ocean',                                   'commonly_eaten', 'bigger_than_a_microwave']\n",
    "        self.obj_feats = ['feathers', 'produce_eggs', 'produce_milk', 'fly', 'swim', 'have_teeth', 'have_a_backbone', 'take_breaths', 'fins', 'zero_legs',                           'two_legs', 'four_legs', 'five_legs', 'six_legs', 'eight_legs', 'have_a_tail', 'type_of_mammal', 'type_of_bird', 'reptile', 'type_of_fish',                           'type_of_amphibian', 'type_of_insect', 'pink-colored', 'black_and_white', 'orange-colored', 'red', 'green', 'yellow', 'stripes',\n",
    "                          'horns_or_antlers', 'have_tusks', 'active_mainly_at_night', 'have_a_shell', 'sting', 'in_a_cold_climate']\n",
    "\n",
    "    # ====================================================\n",
    "    # Utility functions to describe some objects and debug\n",
    "    # ====================================================\n",
    "\n",
    "    def describe_knowledge_base(self):\n",
    "        print('There are {0} objects and {1} features for each object.'.format(self.y.shape[0], self.X.shape[1]))\n",
    "\n",
    "    def undo_play(self):\n",
    "        \"\"\"\n",
    "        This function will delete the last row of our KB, useful for debugging and keeping only the real play rounds, not the prototyping ones.\n",
    "        Also deletes last row of the stats df. Don't call reset_stats() before calling undo_play().\n",
    "        Arg:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        #\n",
    "        last_index_kb = self.kn.shape[0] -1\n",
    "        self.kn = self.kn.drop(index = last_index_kb)\n",
    "        last_index_stats = self.stats.shape[0]-1\n",
    "        self.stats = self.stats.drop(index = last_index_stats)\n",
    "        self.save_progress()\n",
    "\n",
    "    def save_progress(self):\n",
    "        \"\"\"\n",
    "        Saves the current state of kb and stats\n",
    "        Arg:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        #making sure we don't have duplicated rows\n",
    "        self.kn = self.kn.drop_duplicates().copy()\n",
    "        self.kn.to_csv(self.kn_file_name, index = False)\n",
    "        self.stats.to_csv(self.stats_file_name, index = False)\n",
    "\n",
    "    def reset_stats(self):\n",
    "        \"\"\"\n",
    "        Function to reset the stats dataframe in case it gets messy\n",
    "        Arg:\n",
    "\n",
    "        Returns:\n",
    "\n",
    "        \"\"\"\n",
    "        self.stats = pd.DataFrame({'n_questions':[], 'result':[]})\n",
    "        self.save_progress()\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # The following methods are for sampling the feature to ask about in each stage of the game, based on the\n",
    "    # split cardinality ratio.\n",
    "    # ====================================================\n",
    "\n",
    "\n",
    "    def get_distinguishing_feats(self):\n",
    "        \"\"\"\n",
    "        Ranks the features in X in ascending order of abs(1-SCR) and filters out those that contain either all 0s or all 1s\n",
    "        (i.e. those that cannot be used to distinguish between objects).\n",
    "\n",
    "        Arg:\n",
    "        Returns:\n",
    "            A pandas series of features ranked by abs(1-SCR) ascending, with non-distinguishing features removed.\n",
    "        \"\"\"\n",
    "        # Rank the features, drop the NaNs that were put there by dist_from_1(), and return what remains.\n",
    "        ranked = self.rank_features()\n",
    "        distinguishing_feats = ranked.dropna()\n",
    "        return distinguishing_feats\n",
    "\n",
    "    def rank_features(self):\n",
    "        \"\"\"\n",
    "        Ranks all features in df by their increasing absolute distance from 1 of the SCR.\n",
    "\n",
    "        Arg:\n",
    "        Returns:\n",
    "            A pandas series of features ranked by abs(1-SCR) ascending\n",
    "        \"\"\"\n",
    "        return self.X.apply(self.dist_from_1).sort_values()\n",
    "\n",
    "    def dist_from_1(self, feat_col):\n",
    "        \"\"\"\n",
    "        Returns the absolute distance from 1 of the split cardinality ratio for the given column of X.\n",
    "\n",
    "        Arg:\n",
    "            feat_col: a pandas series, one column in the data frame.\n",
    "        Returns:\n",
    "            A float if there are both 0s and 1s in the column, else np.nan\n",
    "        \"\"\"\n",
    "        counts = feat_col.value_counts()\n",
    "        if len(counts) == 2:  # i.e. if there are both 1s and 0s in the column\n",
    "            ratio = counts[0] / counts[1]\n",
    "            return abs( 1 - ratio )\n",
    "        return np.nan  # Features that get NaNs are filtered out later :)\n",
    "\n",
    "    def sample_feature(self, distinguishing_feats):\n",
    "        \"\"\"\n",
    "        Ranks the features in X, creates a probability distribution from the ranking, and samples a feature\n",
    "        according to this probability distribution, returning this as the feature to ask about.\n",
    "\n",
    "        Arg:\n",
    "            distinguishing_feats: pandas series of features ranked by abs(1-SCR) ascending, with non-distinguishing\n",
    "                                  features removed.\n",
    "        Returns:\n",
    "            sampled_feat: A string, the sampled feature to ask about.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get the max value of the distinguishing features (this is the final element, since they're ranked ascending).\n",
    "        max_val = distinguishing_feats[-1]\n",
    "\n",
    "        # Subtract each value in the series from max_val+1; now the features will be sorted descending, and the best features\n",
    "        # to split on will have the highest values.\n",
    "        # (the +1 is there because otherwise the final feature will have probability 0, and we still want it to be eligible,\n",
    "        # if improbable)\n",
    "        ranked_feats_transf = max_val - distinguishing_feats + 1\n",
    "\n",
    "        # Convert to a probability distribution by dividing by the sum of all observations.\n",
    "        feat_prob_dist = ranked_feats_transf / ranked_feats_transf.sum()\n",
    "\n",
    "        # Sample one feature from this distribution and return that feature.\n",
    "        sampled_feat = np.random.choice( feat_prob_dist.index, 1, p = feat_prob_dist )\n",
    "        sampled_feat = str(sampled_feat[0])\n",
    "\n",
    "        return sampled_feat\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # The following methods are for asking the user about the sampled feature, getting their answer, splitting the\n",
    "    # input space accordingly, and updating the probability distribution over animals.\n",
    "    # ====================================================\n",
    "\n",
    "    def get_majority_value_and_extremeness(self, feature):\n",
    "        \"\"\"\n",
    "        Looks at how the values are distributed in the given feature. For use in choosing whether to ask\n",
    "        an unbiased question or a biased question.\n",
    "\n",
    "        Args:\n",
    "            X: pandas dataframe with features as columns, populated by 0s and 1s, one row per instance\n",
    "            feature: a string, the feature we care about.\n",
    "        Returns:\n",
    "            majority: integer, 0 or 1, representing majority value for the given feature\n",
    "            dist_from_equilibrium: float between 0 and 1, representing how out-of-balanced the values for that feature are\n",
    "            (a value close to 1 means that one value completely overpowers the other; a value closer to 0 means that they\n",
    "            are better balanced).\n",
    "        \"\"\"\n",
    "        # Count the number of times 0 and 1 each appear in the column and set the more frequent one as majority.\n",
    "        counts = self.X[feature].value_counts()\n",
    "        majority = counts.idxmax()\n",
    "\n",
    "        # Now compute the percentage of ones and determine how far that percentage is from a 50/50 balance. (Multiplied by\n",
    "        # 2 so that the output distance is in [0, 1], not [0, 0.5] because I think that's more intuitive).\n",
    "        # See interpretation in docstring.\n",
    "\n",
    "        if len(counts) == 2: # i.e. if there are both 1s and 0s in the column\n",
    "            percent_ones = counts[1] / (counts[0] + counts[1])\n",
    "            dist_from_equilibrium = 2 * abs( percent_ones - 0.5 )\n",
    "\n",
    "        else: # if only 0s or only 1s in the column; totally out of balance.\n",
    "            dist_from_equilibrium = 1\n",
    "\n",
    "        return majority, dist_from_equilibrium\n",
    "\n",
    "    def ask_and_get_answer(self, feature, majority_val, extremeness):\n",
    "        \"\"\"\n",
    "        Prints question about the supplied feature and gets the answer (checks validity of input).\n",
    "\n",
    "        Args:\n",
    "            feature: a string, a column in df\n",
    "            majority_val: integer, 0 or 1, representing majority value for the given feature.\n",
    "            extremeness: float between 0 and 1, representing how out-of-balanced the values for that feature are.\n",
    "        Returns:\n",
    "            integer in 0, 1, 2 representing the user's answer\n",
    "        \"\"\"\n",
    "        # Asks and gets answer.\n",
    "        self.ask_about_feature(feature, majority_val, extremeness)\n",
    "        answ_raw = input()\n",
    "\n",
    "        # Checks for bad input.\n",
    "        while answ_raw not in set(['0', '1', '2']):\n",
    "            print('Please give valid input (0=no, 1=yes, 2=unknown).')\n",
    "            answ_raw = input()\n",
    "\n",
    "        # Convert string input to integer (0, 1, or 2) and return.\n",
    "        answ = int(answ_raw)\n",
    "        return answ\n",
    "\n",
    "    def process_answer(self, feature, answ):\n",
    "        \"\"\"\n",
    "        Splits X based on user's answer, adds the answer to the answers dictionary, and modifies the probability\n",
    "        distribution over animals based on the answer.\n",
    "\n",
    "        Args:\n",
    "            feature: a string, a column in df\n",
    "            answ: integer in 0, 1, 2 representing the user's answer\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        # Add answer to the answers database\n",
    "        self.answers[feature] = answ\n",
    "\n",
    "        # If the answer is 0 or 1, split dataset, returning only those instances where the answer holds, and update\n",
    "        # the probability distribution over animals accordingly.\n",
    "        if answ == 0:\n",
    "            self.update_animal_probdist(feature, 0)\n",
    "            self.split_df_on_feature(feature, answ)\n",
    "        elif answ == 1:\n",
    "            self.update_animal_probdist(feature, 1)\n",
    "            self.split_df_on_feature(feature, answ)\n",
    "\n",
    "        # If the answer is 2, only remove the feature from the dataset; don't split dataset and don't update probdist.\n",
    "        else:\n",
    "            self.X = self.X.drop(columns=[feature])\n",
    "\n",
    "    def split_df_on_feature(self, feature, answer):\n",
    "        \"\"\"\n",
    "        Returns subset of df where df[feature]==answer and drops feature from columns in df.\n",
    "\n",
    "        Args:\n",
    "            feature: string, the column name to split on\n",
    "            answer: int, 0 or 1, reflecting which subset of the dataframe to keep\n",
    "        Returns:\n",
    "            pandas dataframe with features as columns (subset of df).\n",
    "        \"\"\"\n",
    "        self.X = self.X[self.X[feature] == answer].drop(columns=[feature])\n",
    "\n",
    "    def update_animal_probdist(self, feature_asked, answ):\n",
    "        \"\"\"\n",
    "        Given a user's answers to a question about a particular feature, update the probability distribution over animals.\n",
    "\n",
    "        Args:\n",
    "            feature_asked: a string, the feature just asked about\n",
    "            answ: an integer, the user's response\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "\n",
    "        # Set the index of kn to the animal column for easy combination with the probability distribution.\n",
    "        kn = self.kn.set_index('animal')\n",
    "\n",
    "        # Extract the column in kn corresponding to the feature we asked about.\n",
    "        kn_col = pd.Series(kn[feature_asked])  # Copy this column before modifying it, so that we don't modify kn!\n",
    "\n",
    "        # Halve current value if incompatible.\n",
    "        # To do this, replace all wrong answers with 2s and correct answers by 1s,\n",
    "        # and divide by kn_col (divides mismatches by 2 and matches by 1, i.e. matches stay same)\n",
    "        if answ == 1:\n",
    "            kn_col = np.where(kn_col == 0, 2, kn_col)\n",
    "            self.y_probdist = self.y_probdist / kn_col\n",
    "        elif answ == 0:\n",
    "            kn_col = np.where(kn_col == 1, 2, 1)\n",
    "            self.y_probdist = self.y_probdist / kn_col\n",
    "\n",
    "    def ask_about_feature(self, feat_name, majority_val, extremeness):\n",
    "        \"\"\"\n",
    "        This function prints out a natural language question (either biased or not) based on the feature name,\n",
    "        e.g. biased positive: \"Your animal does have wings, doesn't it?\", non-biased: \"Does your animal have wings?\".\n",
    "        No biased negative because of ambiguity of answer (what does it mean to answer 'no' to 'Your animal is yellow,\n",
    "        isn't it?').\n",
    "\n",
    "        Args:\n",
    "            feat_name: string, name of feature to split dataset on\n",
    "            majority_val: integer, 0 or 1, representing majority value for the given feature.\n",
    "            extremeness: float between 0 and 1, representing how out-of-balanced the values for that feature are.\n",
    "        Prints:\n",
    "            A string, the natural language question asking about that feature.\n",
    "        Returns:\n",
    "            Nothing.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize bias threshold\n",
    "        bias_threshold = 0.65\n",
    "\n",
    "        # PREPROCESSING OF FEATURE NAMES\n",
    "        vowels = \"aeiou\"\n",
    "        feat_name = feat_name.replace(\"_\",\" \") # replace all underscores by blank spaces\n",
    "        word = feat_name.partition(\" \") # splits into a 3-tuple at first space, e.g. ('has', ' ', 'many good friends')\n",
    "\n",
    "        # convert feature into SpaCy doc (i.e. sequence of tokens)\n",
    "        doc = nlp(feat_name)\n",
    "        # print(\"FEATURE:\", doc)\n",
    "\n",
    "        # The question type is decided based on the POS of the first word in the feature name\n",
    "        first_token = doc[0]\n",
    "        token_pos = first_token.pos_\n",
    "        # print('POS:', token_pos)\n",
    "\n",
    "        # BIASED POSITIVE QUESTIONS: \"Your animal has wings, doesn't it?\"\n",
    "        if majority_val == 1 and extremeness > bias_threshold:\n",
    "            # print('BIASED QUESTION')\n",
    "\n",
    "            # Participles, adjectives, adverbs\n",
    "            if (token_pos == \"VERB\" and feat_name[-2:] == \"ed\") or token_pos == \"ADJ\" or token_pos == \"ADV\":\n",
    "                question = f\"Your animal is {feat_name}, isn't it?\"\n",
    "\n",
    "            # Plural nouns, nouns preceded by determiner\n",
    "            elif (token_pos == \"NOUN\" and feat_name[-1] == \"s\") or token_pos == \"DET\" or token_pos == 'NUM':\n",
    "                question = f\"Your animal has {feat_name}, doesn't it?\"\n",
    "\n",
    "            # Singular nouns: distinction of vowel-initial and consonant-initial nouns\n",
    "            elif token_pos == \"NOUN\" and feat_name[-1] != \"s\":\n",
    "                if feat_name[0].lower() in vowels:\n",
    "                    question = f\"Your animal is an {feat_name}, isn't it?\"\n",
    "                else:\n",
    "                    question = f\"Your animal is a {feat_name}, isn't it?\"\n",
    "\n",
    "            # Verbs: Third person singular, distinction of multiple-element feat_names and single-element feat_names\n",
    "            # and auxiliaries, i.e. possessive 'has'\n",
    "            elif token_pos == \"VERB\":\n",
    "                if word[2] != \"\": # if feat_name consists of more than 1 word\n",
    "#                     question = f\"Your animal {lexeme(first_token)[1]} {word[2]}, doesn't it?\"\n",
    "                    ## lexeme() is a terrible generator that always crashes on the first run-through but works fine after :(\n",
    "                    question = f\"Your animal {str(first_token)+'s'} {word[2]}, doesn't it?\"\n",
    "                else: # if feat_name consists of only 1 word\n",
    "                    question = f\"Your animal {str(first_token)+'s'}, doesn't it?\"\n",
    "\n",
    "            # Auxiliaries (i.e. 'have')\n",
    "            elif token_pos == 'AUX':\n",
    "                question = f\"Your animal has {word[2]}, doesn't it?\"\n",
    "\n",
    "            # Adpositions\n",
    "            elif token_pos == \"ADP\":\n",
    "                question = f\"Your animal lives {feat_name}, doesn't it?\"\n",
    "\n",
    "            # In case none of these conditions are triggered (shouldn't happen, but, just in case), give up and\n",
    "            # ask about the feature name alone\n",
    "            else:\n",
    "                question = feat_name+'?'\n",
    "\n",
    "        # NON-BIASED QUESTION: \"Does your animal have wings?\"\n",
    "        else:\n",
    "            # print('UNBIASED QUESTION')\n",
    "\n",
    "            if (token_pos == \"VERB\" and feat_name[-2:]== \"ed\") or token_pos == \"ADJ\" or token_pos == \"ADV\":\n",
    "                question = f\"Is your animal {feat_name}?\"\n",
    "\n",
    "            elif (token_pos == \"NOUN\" and feat_name[-1] == \"s\") or token_pos == \"DET\" or token_pos == 'NUM':\n",
    "                question = f\"Does your animal have {feat_name}?\"\n",
    "\n",
    "            elif token_pos == \"NOUN\" and feat_name[-1] != \"s\":\n",
    "                if feat_name[0].lower() in vowels:\n",
    "                    question = f\"Is your animal an {feat_name}?\"\n",
    "                else:\n",
    "                    question = f\"Is your animal a {feat_name}?\"\n",
    "\n",
    "            elif token_pos == 'AUX':\n",
    "                question = f'Does your animal have {word[2]}?'\n",
    "\n",
    "            elif token_pos == \"VERB\":\n",
    "                question = f\"Does your animal {feat_name}?\"\n",
    "\n",
    "            elif token_pos == \"ADP\":\n",
    "                question = f\"Does your animal live {feat_name}?\"\n",
    "\n",
    "            else:\n",
    "                question = feat_name+'?'\n",
    "\n",
    "        print('Q'+str(self.counter)+': '+question)\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # The following methods are for once the features are exhausted. They ask about the animals in order of\n",
    "    # most likely to least likely.\n",
    "    # ====================================================\n",
    "\n",
    "    def guess_objs_from_probdist(self):\n",
    "        \"\"\"\n",
    "        To be used once the dataset cannot be split by features anymore but multiple objects still remain.\n",
    "        Guesses objects in order of descending probability.\n",
    "\n",
    "        Args:\n",
    "        Returns:\n",
    "            Nothing.\n",
    "        \"\"\"\n",
    "        # Sort values descending, so the highest-probability animals are first.\n",
    "        self.y_probdist.sort_values(ascending=False, inplace=True)\n",
    "\n",
    "        # Initialise list to collect names of animals already guessed (this is to avoid asking multiple times about\n",
    "        # an animal if it is given multiple times in the knowledge base; now, we only guess each animal once,\n",
    "        # corresponding to its highest-probability instance in y_probdist)\n",
    "        guessed_animals = set()\n",
    "\n",
    "        # Go through animal in descending order of probability and guess. Skip the animal if it's already been asked.\n",
    "        for animal in self.y_probdist.index:\n",
    "            if self.counter <= 20:\n",
    "                if animal not in guessed_animals:\n",
    "\n",
    "                    self.ask_about_object(animal)\n",
    "                    guessed_animals.add(animal)\n",
    "\n",
    "                    self.counter += 1\n",
    "\n",
    "                    # Get user input for answer and check that it's OK.\n",
    "                    answ_raw = input()\n",
    "                    # Checks for bad input.\n",
    "                    while answ_raw not in set(['0', '1', '2']):\n",
    "                        print('Please give valid input (0=no, 1=yes, 2=unknown).')\n",
    "                        answ_raw = input()\n",
    "                    answ = int(answ_raw)\n",
    "\n",
    "                    if answ == 1:\n",
    "                        self.endgame_win()\n",
    "                        break\n",
    "\n",
    "            # Lose because exceeded 20 questions\n",
    "            else:\n",
    "                self.quick_endgame_lose() if self.quick_endgame else self.endgame_lose()\n",
    "                return\n",
    "\n",
    "    def ask_about_object(self, obj_name):\n",
    "        \"\"\"\n",
    "        This function prints out a natural language question based on the object name,\n",
    "        e.g. \"Are you thinking of an ocelot?\"\n",
    "\n",
    "        Arg:\n",
    "            obj_name: string, name of object to guess.\n",
    "        Prints:\n",
    "            A string, the natural language question guessing that object.\n",
    "        Returns:\n",
    "            Nothing.\n",
    "        \"\"\"\n",
    "\n",
    "        vowels = \"aeiou\" # Initiate string for vowel/consonant distinction\n",
    "\n",
    "        # Distinction of vowel-initial and consonant-initial nouns\n",
    "        if obj_name[0].lower() in vowels:\n",
    "            question = f\"Are you thinking of an {obj_name}?\"\n",
    "        else:\n",
    "            question = f\"Are you thinking of a {obj_name}?\"\n",
    "\n",
    "        print('Q'+str(self.counter)+': '+question)\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # The following functions are for the endgame: if the system guesses right, it wins. Otherwise, it loses.\n",
    "    # ====================================================\n",
    "    #Auxiliary functions for the endgame_lose phase:\n",
    "\n",
    "    def our_similarity(self, x, y):\n",
    "        \"\"\"\n",
    "        This function will count how many values x and y have in common\n",
    "        Arg:\n",
    "            The rows we are comparing\n",
    "        Returns:\n",
    "            Count of common features\n",
    "        \"\"\"\n",
    "        li = []\n",
    "        \n",
    "        for i, el in enumerate(x):\n",
    "            if el == y[i]:\n",
    "                li.append(1)\n",
    "            else:\n",
    "                li.append(0)\n",
    "        \n",
    "        return sum(li)\n",
    "\n",
    "    def sim_argmax(self):\n",
    "        \"\"\"\n",
    "        Using correlation between rows to measure similarity and retrieve index and most similar row\n",
    "\n",
    "        Arg:\n",
    "            The new row that we will compare to every pre-existing row\n",
    "        Returns:\n",
    "            The index of the argmax and it's similarity value\n",
    "        \"\"\"\n",
    "        self.new_row = pd.Series(data = self.new_row[1:], index = self.kn.set_index('animal').columns)\n",
    "        corrs = np.asarray(self.kn.set_index('animal').corrwith(self.new_row, axis = 1))\n",
    "        #getting argmax\n",
    "        argmax = np.argmax(np.abs(corrs))\n",
    "        return argmax, corrs[argmax]\n",
    "\n",
    "    # ====================================================\n",
    "\n",
    "    def endgame_lose(self):\n",
    "        \"\"\"\n",
    "        Handles the case in which we are not able to guess the user's animal.\n",
    "        First it asks for the correct answer. If the correct answer was already in the dataset, it will create a new row combining the given answers and the existing data on that animal.\n",
    "        If the correct answer was not on the dataset, it will create a new row taking into account the answers provided by the user and the most similar pre-existing animal on the database.\n",
    "        After adding this new information to the kb, it will update the stats file and save the game's progress.\n",
    "        Arg:\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        #======================================\n",
    "\n",
    "        # EP ADDED\n",
    "        print(self.answers)\n",
    "\n",
    "        #Swallowing pride\n",
    "        print('Dangit, you were too smart for me!')\n",
    "\n",
    "        #======================================\n",
    "\n",
    "        #Getting correct answer\n",
    "        print('Which object were you thinking about?')\n",
    "        correct_answer = '_'.join(input().lower().split())\n",
    "        #adding the correct answer to the answers dict\n",
    "        self.answers[self.y.name] = correct_answer\n",
    "        #print(self.answers)\n",
    "        print('Smart choice!')\n",
    "\n",
    "        #=======================================\n",
    "\n",
    "        # Getting rid of the answers that received a 2\n",
    "        self.answers = {k:v for k, v in self.answers.items() if v!=2}\n",
    "\n",
    "        #=======================================\n",
    "\n",
    "        # If the correct answer is already in our dataset\n",
    "        if correct_answer in self.y.unique():\n",
    "            # If the user's answers contradict our KB we will add a new row to the KB with the new information\n",
    "\n",
    "            #temporary array to keep the updated row\n",
    "            correct_answer_index = np.where(self.y==correct_answer)[0][0]\n",
    "            self.new_row = self.kn.iloc[[correct_answer_index]].copy()\n",
    "\n",
    "            #update process\n",
    "            for attribute, value in self.answers.items():\n",
    "                if type(value) != str: #making sure to not compare the animal name\n",
    "                    if (value == self.new_row[attribute]).bool() == False: #diff than in our KB\n",
    "                                self.new_row[attribute] = value\n",
    "            self.kn = self.kn.append(self.new_row, ignore_index=True)\n",
    "\n",
    "            #adding result to stats\n",
    "            new_stats_row = pd.DataFrame({'n_questions':[self.counter-1], 'result':[1]})\n",
    "            self.stats = self.stats.append(new_stats_row, ignore_index=True)\n",
    "\n",
    "        #if correct answer is not yet in our dataset\n",
    "        else:\n",
    "\n",
    "\n",
    "            #retrieving the row that is already in our KB with the highest similarity to the answers provided by the user.\n",
    "            #if there is a tie, we will simply grab the values from the first row having this similarity maximum value.\n",
    "\n",
    "            if self.sim_measure == 'ours':\n",
    "\n",
    "                #blank new row\n",
    "                self.new_row = []\n",
    "\n",
    "                #filling in the new row\n",
    "                for i, attribute in enumerate(self.kn.columns, 0):\n",
    "                    if attribute in self.answers.keys(): #knowledge provided by the user\n",
    "                        self.new_row.append(self.answers[attribute])\n",
    "                    else:\n",
    "                        self.new_row.append(993993)\n",
    "\n",
    "                #using our similarity measure\n",
    "                #we convert to np array and delete the first value with the string 'animal'\n",
    "                rows = [np.asarray(self.kn.iloc[i].copy())[1:] for i in range(self.kn.shape[0])]\n",
    "\n",
    "                #here we store the similarity counts between our new row and every other row in our KB\n",
    "                sim_counts = [self.our_similarity(rows[i], self.new_row) for i in range(len(rows))]\n",
    "\n",
    "                #retrieving the row index corresponding to the animal with the highest similarity and retrieving that row\n",
    "                most_similar_index = np.argmax(sim_counts)\n",
    "                most_similar_row = self.kn.iloc[most_similar_index].copy()\n",
    "\n",
    "                #second round filling in the new row with the missing features coming from the most similar existing row\n",
    "                self.new_row = []\n",
    "\n",
    "                for i, attribute in enumerate(self.kn.columns, 0):\n",
    "                    if attribute in self.answers.keys(): #knowledge provided by the user\n",
    "                        self.new_row.append(self.answers[attribute])\n",
    "                    else:\n",
    "                        #for the features that were not provided by the user we will use our similarity measure to interpolate the missing values from the most similar row.\n",
    "                        self.new_row.append(most_similar_row[i])\n",
    "\n",
    "            elif self.sim_measure == 'corr':\n",
    "                #blank new row\n",
    "                self.new_row = []\n",
    "\n",
    "                #filling in the new row\n",
    "                for i, attribute in enumerate(self.kn.columns, 0):\n",
    "                    if attribute in self.answers.keys(): #knowledge provided by the user\n",
    "                        self.new_row.append(self.answers[attribute])\n",
    "                    else:\n",
    "                        self.new_row.append(993993)\n",
    "                self.temp = self.new_row\n",
    "                #using pandas correlation between rows to retrieve similarities\n",
    "                most_similar_index, value = self.sim_argmax()\n",
    "                most_similar_row = self.kn.iloc[most_similar_index].copy()\n",
    "                if value >0:\n",
    "                    #positive correlation so we'll copy the values from the most similar row\n",
    "                    #second round filling in the new row with the missing features coming from the most similar existing row\n",
    "                    self.new_row = []\n",
    "\n",
    "                    for i, attribute in enumerate(self.kn.columns, 0):\n",
    "                        if attribute in self.answers.keys(): #knowledge provided by the user\n",
    "                            self.new_row.append(self.answers[attribute])\n",
    "                        else:\n",
    "                            #for the features that were not provided by the user we will use our similarity measure to interpolate the missing values from the most similar row.\n",
    "                            self.new_row.append(most_similar_row[i])\n",
    "                elif value <= 0:\n",
    "                    #negative correlation so we'll invert the values from the most different row\n",
    "                    self.new_row = []\n",
    "\n",
    "                    for i, attribute in enumerate(self.kn.columns, 0):\n",
    "                        if attribute in self.answers.keys(): #knowledge provided by the user\n",
    "                            self.new_row.append(self.answers[attribute])\n",
    "                        else:\n",
    "                            #for the features that were not provided by the user we will use our similarity measure to interpolate the missing values from the most similar row.\n",
    "                            new_val = 0 if most_similar_row[i]==1 else 1\n",
    "                            self.new_row.append(new_val)\n",
    "\n",
    "\n",
    "            #adding it to the KN\n",
    "            final = dict()\n",
    "            for i, at in enumerate(self.kn.columns, 0):\n",
    "                final[at] = self.new_row[i]\n",
    "            self.kn = self.kn.append(final, ignore_index=True)\n",
    "\n",
    "            #updating stats\n",
    "            new_stats_row = pd.DataFrame({'n_questions':[self.counter-1], 'result':[2]})\n",
    "            self.stats = self.stats.append(new_stats_row, ignore_index=True)\n",
    "\n",
    "\n",
    "        #Updating our KB file\n",
    "        self.save_progress()\n",
    "\n",
    "        # Resetting game-dependent variables so we can play again.\n",
    "        self.reset_game()\n",
    "\n",
    "\n",
    "    def endgame_win(self):\n",
    "        \"\"\"\n",
    "            Handles the case in which we guess correctly the user's animal, updates the stats file and saves progress.\n",
    "        \"\"\"\n",
    "        print('Oh yeah! I rock')\n",
    "        new_stats_row = pd.DataFrame({'n_questions':[self.counter-1], 'result':[0]})\n",
    "        self.stats = self.stats.append(new_stats_row, ignore_index=True)\n",
    "        self.save_progress()\n",
    "\n",
    "        # Resetting game-dependent variables so we can play again.\n",
    "        self.reset_game()\n",
    "\n",
    "\n",
    "    def quick_endgame_lose(self):\n",
    "        \"\"\"\n",
    "        Quick version of the losing case for prototyping.\n",
    "        \"\"\"\n",
    "        print('dangit')\n",
    "\n",
    "        # Resetting game-dependent variables so we can play again.\n",
    "        self.reset_game()\n",
    "\n",
    "\n",
    "    def reset_game(self):\n",
    "        \"\"\"\n",
    "        After a game has been won or lost, resets all game-dependent variables to their initial states.\n",
    "        \"\"\"\n",
    "        self.X = self.kn.loc[:, self.kn.columns != 'animal']\n",
    "        self.counter = 1\n",
    "        self.answers = dict()\n",
    "        self.y = self.kn['animal']\n",
    "        self.y_probdist = pd.DataFrame(self.y)\n",
    "        self.y_probdist['prob'] = np.repeat(20, len(self.y))\n",
    "        self.y_probdist = self.y_probdist.set_index('animal')['prob']\n",
    "\n",
    "\n",
    "\n",
    "    # ====================================================\n",
    "    # Finally, the following function is a recursive function that plays the game.\n",
    "    # ====================================================\n",
    "\n",
    "    def play(self):\n",
    "        \"\"\"\n",
    "        Recursively bisects knowledge base based on user input about whether target object matches the feature.\n",
    "        Guesses animals in order of their descending probability, given the user's answers.\n",
    "        \"\"\"\n",
    "\n",
    "        # -----------------------------\n",
    "        # BASE CASE 0: counter > 20\n",
    "        # -----------------------------\n",
    "        if self.counter > 20:\n",
    "            print('TOO MANY QUESTIONS!')\n",
    "            self.quick_endgame_lose() if self.quick_endgame else self.endgame_lose()\n",
    "            return\n",
    "\n",
    "        # -----------------------------\n",
    "        # BASE CASE 1: Only one row left in the data, so only one object compatible with all the answers thus far.\n",
    "        # Guess it (at top of probdist) and further objects in order of decreasing probability.\n",
    "        # -----------------------------\n",
    "\n",
    "        if len(self.X) == 1:\n",
    "            print('ONLY ONE OBJECT LEFT!')\n",
    "            self.guess_objs_from_probdist()  # includes endgame\n",
    "            return\n",
    "\n",
    "        # -----------------------------\n",
    "        # BASE CASE 2: Only one feature left in the data (have asked about all other ones). Will need to ask about that feature,\n",
    "        # subset the data correspondingly, and then go through all remaining objects in descending order of probability.\n",
    "        # -----------------------------\n",
    "\n",
    "        if len(self.X.columns) == 1:\n",
    "            print('ONLY ONE FEATURE LEFT!')\n",
    "            feature_to_split_on = self.X.columns[0]\n",
    "            majority_val, extremeness = self.get_majority_value_and_extremeness(feature_to_split_on)\n",
    "            answ = self.ask_and_get_answer(feature_to_split_on, majority_val, extremeness)\n",
    "            self.process_answer(feature_to_split_on, answ)\n",
    "            self.counter += 1\n",
    "\n",
    "            # If there are no remaining objects to guess after splitting the data on this feature, then endgame_lose().\n",
    "            if len(self.X.index) == 0:\n",
    "                print('NO OBJECTS LEFT TO GUESS!')\n",
    "                self.quick_endgame_lose() if self.quick_endgame else self.endgame_lose()\n",
    "                return\n",
    "            # Otherwise, cycle through all remaining objects until endgame.\n",
    "            else:\n",
    "                self.guess_objs_from_probdist()  # includes endgame\n",
    "                return\n",
    "\n",
    "        # -----------------------------\n",
    "        # BASE CASE 3: There are no more distinguishing features at all, so the dataset can't be divided anymore.\n",
    "        # Will just need to cycle through all remaining objects until endgame.\n",
    "        # -----------------------------\n",
    "\n",
    "        disting_feats = self.get_distinguishing_feats()\n",
    "\n",
    "        # Count the distinguishing features in X (i.e. those that aren't all 0s or all 1s) and cycle through objects\n",
    "        # if there are none.\n",
    "        if len( disting_feats ) == 0:\n",
    "            print('NO MORE DISTINGUISHING FEATURES!')\n",
    "            self.guess_objs_from_probdist()  # includes endgame\n",
    "            return\n",
    "\n",
    "        # -----------------------------\n",
    "        # RECURSIVE CASE: If we get this far, that means we didn't fall into any of the base cases, so the game can be played!\n",
    "        # -----------------------------\n",
    "\n",
    "        # We first want to ask about objective features that distinguish the animals; if there are none, we ask about the\n",
    "        # \"rather subjective\" features, and if there are also none, we ask about subjective features.\n",
    "\n",
    "        # Subset disting_feats for the objective features and sample one from the remaining ranking. If a KeyError\n",
    "        # or IndexError is raised, there aren't any more objective features in disting_feats.\n",
    "        try:\n",
    "            disting_feats_obj = disting_feats.reindex(self.obj_feats).sort_values().dropna()\n",
    "#             print('SAMPLING AN OBJECTIVE FEATURE')\n",
    "            feature_to_split_on = self.sample_feature(disting_feats_obj)\n",
    "        except:\n",
    "\n",
    "            # Subset disting_feats for the rather_subj features. If a KeyError is raised, there aren't any more rather\n",
    "            # subjective features in disting_feats either.\n",
    "            try:\n",
    "                disting_feats_rathersubj = disting_feats.reindex(self.rather_subj_feats).sort_values().dropna()\n",
    "#                 print('SAMPLING A \"RATHER SUBJECTIVE\" FEATURE')\n",
    "                feature_to_split_on = self.sample_feature(disting_feats_rathersubj)\n",
    "\n",
    "            # Would finally need to look at the truly subjective features.\n",
    "            except:\n",
    "                disting_feats_subj = disting_feats.reindex(self.subj_feats).sort_values().dropna()\n",
    "#                 print('SAMPLING A SUBJECTIVE FEATURE')\n",
    "                feature_to_split_on = self.sample_feature(disting_feats_subj)\n",
    "\n",
    "#         # OLD VERSION: Doesn't worry about objective/subjective features; just chooses one and splits on it.\n",
    "#         feature_to_split_on = self.sample_feature(disting_feats)\n",
    "\n",
    "        # print('FEAT:', feature_to_split_on)\n",
    "        majority_val, extremeness = self.get_majority_value_and_extremeness(feature_to_split_on)\n",
    "        answ = self.ask_and_get_answer(feature_to_split_on, majority_val, extremeness)\n",
    "        self.process_answer(feature_to_split_on, answ)\n",
    "        self.counter += 1\n",
    "\n",
    "        self.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting similarity functions\n",
    "def sim_ours(x, y):\n",
    "    \"\"\"\n",
    "    This function will count how many values x and y have in common\n",
    "    Arg:\n",
    "        The rows we are comparing\n",
    "    Returns:\n",
    "        Count of common features\n",
    "    \"\"\"\n",
    "    li = []\n",
    "\n",
    "    for i, el in enumerate(x):\n",
    "        if el == y[i]:\n",
    "            li.append(1)\n",
    "        else:\n",
    "            li.append(0)\n",
    "\n",
    "    return sum(li)\n",
    "\n",
    "def sim_corr_mod(new_row, kn):\n",
    "    \"\"\"\n",
    "    Using correlation between rows to measure similarity and retrieve index and most similar row\n",
    "\n",
    "    Arg:\n",
    "        The new row that we will compare to every pre-existing row\n",
    "    Returns:\n",
    "        The index of the argmax and it's similarity value\n",
    "    \"\"\"\n",
    "    new_row = new_row.drop(columns = ['animal']).iloc[0,:]\n",
    "    corrs = np.asarray(kn.set_index('animal').corrwith(new_row, axis = 1))\n",
    "    with_indices = [(i, abs(corr)) for i, corr in enumerate(corrs)]\n",
    "    \n",
    "    return sorted(with_indices, reverse = True, key = lambda x:x[1])[:5]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [('sea lion', 'seal'), ('hare', 'rabbit'), ('german shepherd', 'dog'), ('humpback whale', 'blue whale'), ('chimpanzee', 'monkey'), ('pitviper', 'snake'), ('gnat', 'housefly')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment:1\n",
      "\n",
      "External animal: sea lion\n",
      "Reference animal: seal\n",
      "\n",
      "Similarity measure: OURS \n",
      "\n",
      "The score for seal is: 60\n",
      "\n",
      "1: seal with a score of 60\n",
      "2: orca with a score of 57\n",
      "3: otter with a score of 57\n",
      "4: wallaby with a score of 57\n",
      "5: walrus with a score of 56\n",
      "\n",
      "\n",
      "Similarity measure: CORRELATIONS \n",
      "\n",
      "The score for seal is: 0.8665407417674348\n",
      "\n",
      "1: seal with a score of 0.8665407417674348\n",
      "2: opossum with a score of 0.737500000000002\n",
      "3: ostrich with a score of 0.7279581560248335\n",
      "4: wallaby with a score of 0.7245839172565539\n",
      "5: monkey with a score of 0.7012526785324503\n",
      "\n",
      "\n",
      "Experiment:2\n",
      "\n",
      "External animal: hare\n",
      "Reference animal: rabbit\n",
      "\n",
      "Similarity measure: OURS \n",
      "\n",
      "The score for rabbit is: 55\n",
      "\n",
      "1: porcupine with a score of 60\n",
      "2: llama with a score of 60\n",
      "3: goose with a score of 59\n",
      "4: vole with a score of 59\n",
      "5: ferret with a score of 59\n",
      "\n",
      "\n",
      "Similarity measure: CORRELATIONS \n",
      "\n",
      "The score for rabbit is: 0.6761234037828128\n",
      "\n",
      "1: llama with a score of 0.860456050815271\n",
      "2: porcupine with a score of 0.8595935661119732\n",
      "3: elephant with a score of 0.8163265306122449\n",
      "4: vole with a score of 0.8126360553720006\n",
      "5: weasel with a score of 0.8102546544402045\n",
      "\n",
      "\n",
      "Experiment:3\n",
      "\n",
      "External animal: german shepherd\n",
      "Reference animal: dog\n",
      "\n",
      "Similarity measure: OURS \n",
      "\n",
      "The score for dog is: 58\n",
      "\n",
      "1: collie with a score of 61\n",
      "2: dalmatian with a score of 59\n",
      "3: chihuahua with a score of 59\n",
      "4: raccoon with a score of 59\n",
      "5: dog with a score of 58\n",
      "\n",
      "\n",
      "Similarity measure: CORRELATIONS \n",
      "\n",
      "The score for dog is: 0.8299007036179753\n",
      "\n",
      "1: cockroach with a score of 0.9194373401534527\n",
      "2: chicken with a score of 0.838874680306905\n",
      "3: crow with a score of 0.8387666014838114\n",
      "4: raccoon with a score of 0.8355990086906567\n",
      "5: deer with a score of 0.8299007036179753\n",
      "\n",
      "\n",
      "Experiment:4\n",
      "\n",
      "External animal: humpback whale\n",
      "Reference animal: blue whale\n",
      "\n",
      "Similarity measure: OURS \n",
      "\n",
      "The score for blue whale is: 57\n",
      "\n",
      "1: dolphin with a score of 59\n",
      "2: porpoise with a score of 59\n",
      "3: blue whale with a score of 57\n",
      "4: walrus with a score of 56\n",
      "5: seal with a score of 56\n",
      "\n",
      "\n",
      "Similarity measure: CORRELATIONS \n",
      "\n",
      "The score for blue whale is: 0.7504015581836772\n",
      "\n",
      "1: dogfish with a score of 0.8387666014838109\n",
      "2: porpoise with a score of 0.8387666014838109\n",
      "3: beaver with a score of 0.7504015581836772\n",
      "4: seal with a score of 0.6937071008248814\n",
      "5: walrus with a score of 0.6709022955020288\n",
      "\n",
      "\n",
      "Experiment:5\n",
      "\n",
      "External animal: chimpanzee\n",
      "Reference animal: monkey\n",
      "\n",
      "Similarity measure: OURS \n",
      "\n",
      "The score for monkey is: 56\n",
      "\n",
      "1: gorilla with a score of 59\n",
      "2: baboon with a score of 58\n",
      "3: human with a score of 57\n",
      "4: wallaby with a score of 57\n",
      "5: baboon with a score of 57\n",
      "\n",
      "\n",
      "Similarity measure: CORRELATIONS \n",
      "\n",
      "The score for monkey is: 0.6937071008248814\n",
      "\n",
      "1: gorilla with a score of 0.8061538461538461\n",
      "2: baboon with a score of 0.7445379237378636\n",
      "3: human with a score of 0.7279581560248328\n",
      "4: wallaby with a score of 0.695362336421376\n",
      "5: baboon with a score of 0.695362336421376\n",
      "\n",
      "\n",
      "Experiment:6\n",
      "\n",
      "External animal: pitviper\n",
      "Reference animal: snake\n",
      "\n",
      "Similarity measure: OURS \n",
      "\n",
      "The score for snake is: 57\n",
      "\n",
      "1: slowworm with a score of 59\n",
      "2: snake with a score of 57\n",
      "3: crocodile with a score of 57\n",
      "4: seasnake with a score of 57\n",
      "5: tuatara with a score of 57\n",
      "\n",
      "\n",
      "Similarity measure: CORRELATIONS \n",
      "\n",
      "The score for snake is: 0.7245839172565535\n",
      "\n",
      "1: slowworm with a score of 0.7681373347487818\n",
      "2: crayfish with a score of 0.7245839172565535\n",
      "3: seasnake with a score of 0.6953623364213759\n",
      "4: snake with a score of 0.6486493048989713\n",
      "5: tuatara with a score of 0.6486493048989713\n",
      "\n",
      "\n",
      "Experiment:7\n",
      "\n",
      "External animal: gnat\n",
      "Reference animal: housefly\n",
      "\n",
      "Similarity measure: OURS \n",
      "\n",
      "The score for housefly is: 59\n",
      "\n",
      "1: cockroach with a score of 60\n",
      "2: termite with a score of 60\n",
      "3: flea with a score of 60\n",
      "4: ladybird with a score of 59\n",
      "5: housefly with a score of 59\n",
      "\n",
      "\n",
      "Similarity measure: CORRELATIONS \n",
      "\n",
      "The score for housefly is: 0.6882906501898401\n",
      "\n",
      "1: clam with a score of 0.7456011350793257\n",
      "2: flamingo with a score of 0.7456011350793257\n",
      "3: termite with a score of 0.7049217690953139\n",
      "4: housefly with a score of 0.6882906501898403\n",
      "5: ladybird with a score of 0.6882906501898401\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, exp in enumerate(tests):\n",
    "   \n",
    "    #getting dataset\n",
    "    df = pd.read_csv('knowledge_base.csv')\n",
    "    \n",
    "    print('Experiment:' + str(i+1) + \"\\n\")\n",
    "    \n",
    "    #animal to use as outsider\n",
    "    an1 = exp[0]\n",
    "    print('External animal: ' + an1)\n",
    "    #animal to keep on df\n",
    "    an2 = exp[1]\n",
    "    print('Reference animal: ' + an2 + \"\\n\")\n",
    "    \n",
    "    #Extract outsider row and delete it from df\n",
    "    outsider = df.loc[df['animal'] == an1].copy()\n",
    "    keep = df.loc[df['animal'] == an2].copy()\n",
    "    df = df.loc[df['animal'] != an1].copy()\n",
    "    \n",
    "    #run both similarities\n",
    "    \n",
    "    #run ours and get indices\n",
    "    ours_sorted = sorted([(i, sim_ours(np.asarray(outsider)[0][1:], np.asarray(current)[1:])) for i, current in df.iterrows()], reverse = True, key=lambda x:x[1])[:5]\n",
    "    ours_i = [i[0]-1 for i in ours_sorted]\n",
    "\n",
    "    #run corr\n",
    "    corr_sorted = sim_corr_mod(outsider, df)\n",
    "    corr_i = [i[0] for i in corr_sorted]\n",
    "    print('Similarity measure: OURS \\n')\n",
    "    print('The score for ' + an2 + \" is: \" + str(sim_ours(np.asarray(outsider)[0][1:], np.asarray(keep)[0][1:]))+\"\\n\")\n",
    "    \n",
    "    for i, e in enumerate(corr_i):\n",
    "        print(str(i+1)+': '+ df.iloc[e].animal+ ' with a score of ' + str(ours_sorted[i][1]))    \n",
    "    print(\"\\n\")\n",
    "    print('Similarity measure: CORRELATIONS \\n')\n",
    "    print('The score for ' + an2 + \" is: \" + str(outsider.drop(columns = 'animal').iloc[0].corr(keep.drop(columns = 'animal').iloc[0]))+'\\n')\n",
    "    for i, e in enumerate(ours_i):\n",
    "        print(str(i+1)+': '+ df.iloc[e].animal + ' with a score of ' + str(corr_sorted[i][1]))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#animal to use as outsider\n",
    "an1 = 'hare'  \n",
    "#animal to keep on df\n",
    "an2 = 'rabbit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract outsider row and delete it from df\n",
    "outsider = df.loc[df['animal'] == 'hare'].copy()\n",
    "keep = df.loc[df['animal'] == 'rabbit'].copy()\n",
    "df = df.loc[df['animal'] != 'hare'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run both similarities\n",
    "#run ours and get indices!\n",
    "ours_sorted = sorted([(i, sim_ours(np.asarray(outsider)[0][1:], np.asarray(current)[1:])) for i, current in df.iterrows()], reverse = True, key=lambda x:x[1])[:5]\n",
    "ours_sorted\n",
    "ours_i = [i[0]-1 for i in ours_sorted]\n",
    "ours_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run corr\n",
    "corr_sorted = sim_corr_mod(outsider, df)\n",
    "corr_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The score for ' + an2 + \" is: \" + str(outsider.drop(columns = 'animal').iloc[0].corr(keep.drop(columns = 'animal').iloc[0])))\n",
    "for i, e in enumerate(ours_i):\n",
    "    print(str(i+1)+': '+ df.iloc[e].animal + ' with a score of ' + str(corr_sorted[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The score for ' + an2 + \" is: \" + str(sim_ours(np.asarray(outsider)[0][1:], np.asarray(keep)[0][1:])))\n",
    "for i, e in enumerate(corr_i):\n",
    "    print(str(i+1)+': '+ df.iloc[e].animal+ ' with a score of ' + str(ours_sorted[i][1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
