{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of the Switchboard Dialog Act Corpus\n",
    "\n",
    "This notebook aims to perform preprocessing of data contained in the Switchboard Dialog Act Corpus (SwDA). To generate Natural Language Questions we wanted to use SWDA question structures as a reference point. The code concentrates on the POS-Tags provided by the spaCy library. Since we want to generate Polar Questions for the 20 Questions game, here we explore the POS-templates of Yes/No questions (indicated by the act-tag \"qy\" in the SwDA Corpus).\n",
    "\n",
    "The results of our 5 most-used patterns shows that Yes/No questions follow the POS-Tag-pattern: **VERB**-**PRON**-**?**. For our purpose, this gives us question structures such as: \n",
    "\n",
    "\n",
    "|POS-Tags|Example|  \n",
    "|---|---|\n",
    "|VERB, PRON, VERB, DET, NOUN|\"Does it have (a) tail?\"|\n",
    "|VERB, PRON, VERB, ADP, DET|\"Does it live in a ...?\"|\n",
    "|VERB, PRON, ADJ|\"Is it big?\"| "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import swda\n",
    "from swda import CorpusReader\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "corpus = CorpusReader('swda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "transcript 1155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3788 entries, 0 to 3787\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Index   3788 non-null   object\n",
      " 1   Tag     3788 non-null   object\n",
      " 2   Text    3788 non-null   object\n",
      " 3   POS     3788 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 148.0+ KB\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This piece of code creates a dataframe with useful information for the upcoming question-generation part.\"\"\"\n",
    "    \n",
    "len_qy = 0\n",
    "\n",
    "# indicate column names, this is the information we need\n",
    "df = pd.DataFrame(columns=['Index', 'Tag','Text','POS'])\n",
    "\n",
    "# iterate over swda transcripts and append information to dataframe\n",
    "for trans in corpus.iter_transcripts():\n",
    "    for utt in trans.utterances:\n",
    "        if utt.act_tag == \"qy\":\n",
    "            df.loc[len_qy] = [utt.utterance_index, utt.act_tag, utt.text, utt.pos]\n",
    "            len_qy += 1\n",
    "\n",
    "# get information about dataframe structure\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Text</th>\n",
       "      <th>POS</th>\n",
       "      <th>Spacy_POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83</td>\n",
       "      <td>qy</td>\n",
       "      <td>Were you --</td>\n",
       "      <td>Were/VBD you/PRP --/:</td>\n",
       "      <td>['VERB', 'PRON']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>qy</td>\n",
       "      <td>Are you in Texas? /</td>\n",
       "      <td>Are/VBP you/PRP in/IN Texas/NNP ?/.</td>\n",
       "      <td>['VERB', 'PRON', 'ADP', 'PROPN']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>qy</td>\n",
       "      <td>I probably would have done, {D you know, } jus...</td>\n",
       "      <td>I/PRP probably/RB would/MD have/VB done/VBN ,/...</td>\n",
       "      <td>['PRON', 'ADV', 'VERB', 'VERB', 'VERB', 'NOUN'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>qy</td>\n",
       "      <td>Are you a Vietnam veteran, Dudley?  &lt;Music&gt;. /</td>\n",
       "      <td>Are/VBP you/PRP a/DT Vietnam/NNP veteran/NN ,/...</td>\n",
       "      <td>['VERB', 'PRON', 'DET', 'PROPN', 'NOUN', 'PROP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>qy</td>\n",
       "      <td>Do you have family who were in the Vietnam War? /</td>\n",
       "      <td>Do/VBP you/PRP have/VB family/NN who/WP were/V...</td>\n",
       "      <td>['VERB', 'PRON', 'VERB', 'NOUN', 'PRON', 'VERB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Index Tag                                               Text  \\\n",
       "0    83  qy                                        Were you --   \n",
       "1    46  qy                                Are you in Texas? /   \n",
       "2    29  qy  I probably would have done, {D you know, } jus...   \n",
       "3     1  qy     Are you a Vietnam veteran, Dudley?  <Music>. /   \n",
       "4     5  qy  Do you have family who were in the Vietnam War? /   \n",
       "\n",
       "                                                 POS  \\\n",
       "0                              Were/VBD you/PRP --/:   \n",
       "1                Are/VBP you/PRP in/IN Texas/NNP ?/.   \n",
       "2  I/PRP probably/RB would/MD have/VB done/VBN ,/...   \n",
       "3  Are/VBP you/PRP a/DT Vietnam/NNP veteran/NN ,/...   \n",
       "4  Do/VBP you/PRP have/VB family/NN who/WP were/V...   \n",
       "\n",
       "                                           Spacy_POS  \n",
       "0                                   ['VERB', 'PRON']  \n",
       "1                   ['VERB', 'PRON', 'ADP', 'PROPN']  \n",
       "2  ['PRON', 'ADV', 'VERB', 'VERB', 'VERB', 'NOUN'...  \n",
       "3  ['VERB', 'PRON', 'DET', 'PROPN', 'NOUN', 'PROP...  \n",
       "4  ['VERB', 'PRON', 'VERB', 'NOUN', 'PRON', 'VERB...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"We now want to add a new column to our dataframe with SpaCy POS-Tags to compare those \n",
    "    with the predefined ones. Those are much easier to process later on.\"\"\"\n",
    "\n",
    "pos_tags=[]\n",
    "\n",
    "# access the text column of each row and create POS-Tags via SpaCy\n",
    "for row in df[\"Text\"]: \n",
    "    doc = nlp(row)\n",
    "    tags = []\n",
    "    for token in doc: \n",
    "        tags.append(token.pos_) \n",
    "    pos_tags.append(tags)\n",
    "\n",
    "    \n",
    "\"\"\"Cleaning step to remove POS-Tags from our list that are not informative,\n",
    "    i.e. \"SPACE\" = blank spaces, \"SYM\" = other symbols, \"PUNCT\" = punctuation symbols, \n",
    "    \"X\" = other and \"INTJ\" = interjections.\"\"\"\n",
    "\n",
    "clean = [\"SPACE\", \"SYM\", \"PUNCT\", \"X\", \"INTJ\"]\n",
    "\n",
    "for item in pos_tags:\n",
    "    for element in clean: \n",
    "        while element in item: \n",
    "            item.remove(element)     \n",
    "      \n",
    "# create new column containing spaCy POS-Tags\n",
    "df[\"Spacy_POS\"]= pos_tags\n",
    "\n",
    "# convert datatype of new column to string\n",
    "df['Spacy_POS']= df['Spacy_POS'].astype(str)\n",
    "\n",
    "# this is how our dataframe looks like after adding the SpaCy POS-Tags and performing the cleaning step\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1332 unique POS-Tag combinations.\n",
      "\n",
      "The five most used combinations are:\n",
      "    Occurrences                         POS_Tags\n",
      "0          153    (VERB, PRON, VERB, DET, NOUN)\n",
      "1           90                     (VERB, PRON)\n",
      "2           74  (VERB, PRON, CCONJ, VERB, PRON)\n",
      "3           69   (PROPN, VERB, PRON, VERB, DET)\n",
      "4           61               (VERB, PRON, VERB)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"We want to get information about how the sentences start/the general structure of the sentence.\n",
    "    This piece of code creates a dictionary with the unique patterns of POS-Tags that can be found in the corpus\"\"\"\n",
    "\n",
    "pos_5 = [] #using first 5 pos tags of every sentence \n",
    "\n",
    "for tag in pos_tags:\n",
    "    pos_5.append(tag[:5])\n",
    "    \n",
    "# get unique sentence-POS combinations\n",
    "unique_pos = Counter([tuple(i) for i in pos_5])\n",
    "\n",
    "\"\"\"Lets have a look at the most frequent POS-Tag templates\"\"\"\n",
    "   \n",
    "most_used_5 = sorted(unique_pos, key=unique_pos.get, reverse=True)[:5]\n",
    "\n",
    "print(\"We have\", len(unique_pos), \"unique POS-Tag combinations.\")\n",
    "\n",
    "# sort dictionary unique_pos to get most frequent \n",
    "freq = sorted(((v,k) for k,v in unique_pos.items()), reverse=True) \n",
    "\n",
    "# create frequency dataframe \n",
    "freq_df = pd.DataFrame(freq, columns=[\"Occurrences\", \"POS_Tags\"])\n",
    "print(\"\\nThe five most used combinations are:\\n\", freq_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
